{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m2M2AZLAnXbV"
      },
      "source": [
        "# DeepLab - Video Segmentation - Xception 65"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9zAeOnVVct5E"
      },
      "source": [
        "## Import libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wBU_Qhf20pGs",
        "outputId": "83524753-4eb8-48c8-e6f5-14fbea3e6f8a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tensorflow version: 2.9.2\n"
          ]
        }
      ],
      "source": [
        "from DeepLabModel import DeepLabModel\n",
        "from glob import glob\n",
        "from google.colab.patches import cv2_imshow\n",
        "from imageio import mimread\n",
        "from io import BytesIO\n",
        "from matplotlib import  gridspec\n",
        "from matplotlib.style import use\n",
        "from PIL import Image\n",
        "from six.moves import urllib\n",
        "from sklearn.metrics import  confusion_matrix\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tabulate import tabulate\n",
        "from tqdm import tqdm\n",
        "\n",
        "import cv2\n",
        "import IPython\n",
        "import keras.backend as K\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import os\n",
        "import random\n",
        "#import tarfile\n",
        "import tempfile\n",
        "import tensorflow as tf\n",
        "\n",
        "use('seaborn')\n",
        "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
        "\n",
        "print(f'Tensorflow version: {tf.__version__}')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def create_colormap():\n",
        "    \"\"\"\n",
        "    Retunr:\n",
        "        NumPy array with a colormap to visualize the segmentation results.\n",
        "    \"\"\"\n",
        "    colormap = np.array([\n",
        "        [128,  64, 128],\n",
        "        [244,  35, 232],\n",
        "        [ 70,  70,  70],\n",
        "        [102, 102, 156],\n",
        "        [190, 153, 153],\n",
        "        [153, 153, 153],\n",
        "        [250, 170,  30],\n",
        "        [220, 220,   0],\n",
        "        [120, 155,  42],\n",
        "        [152, 251, 152],\n",
        "        [ 93, 165, 227],\n",
        "        [220,  20,  60],\n",
        "        [255,   0,   0],\n",
        "        [ 34,  34, 142],\n",
        "        [  0,   0,  70],\n",
        "        [  0,  60, 100],\n",
        "        [  0,  80, 100],\n",
        "        [  0,   0, 230],\n",
        "        [119,  11,  32],\n",
        "        [  0,   0,   0]], dtype=np.uint8)\n",
        "    return colormap"
      ],
      "metadata": {
        "id": "y4TXKZHvXVSq"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def label_to_color_image(label):\n",
        "    \"\"\"\n",
        "    Parameters:\n",
        "        label: 2D array that stores the segmentation label.\n",
        "\n",
        "    Return:\n",
        "        Segmentation map: a 2D array with float values. The array element is an indexed color by correspondent element in the input label. \n",
        "        In other words, the return is an image like the original image, but the pixels will be segmented with the network prediction.\n",
        "    \"\"\"\n",
        "    \n",
        "    # Error if the input label doesn't have two dimensions.\n",
        "    if label.ndim != 2:\n",
        "        raise ValueError('Expect 2-D input label')\n",
        "\n",
        "    colormap = create_colormap()\n",
        "\n",
        "    # Error if label index is larger than the maximum index of colormap list.\n",
        "    if np.max(label) >= len(colormap):\n",
        "        raise ValueError('label value too large.')\n",
        "\n",
        "    return colormap[label]"
      ],
      "metadata": {
        "id": "9HNfvlp3XVPE"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Label names, class identifiers and colors associated with it."
      ],
      "metadata": {
        "id": "LKRYDu-huhTj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "LABEL_NAMES = np.asarray([\n",
        "    'road', 'sidewalk', 'building', 'wall', 'fence', 'pole', 'traffic light',\n",
        "    'traffic sign', 'vegetation', 'terrain', 'sky', 'person', 'rider', 'car', 'truck',\n",
        "    'bus', 'train', 'motorcycle', 'bicycle', 'void'])\n",
        "\n",
        "print(f'Number of labels: {len(LABEL_NAMES)}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N65-T8BBxtO9",
        "outputId": "5d03f4f3-e224-45df-f026-8c97c09408f2"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of labels: 20\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Class indentifiers. \n",
        "FULL_LABEL_MAP = np.arange(len(LABEL_NAMES)).reshape(len(LABEL_NAMES), 1) \n",
        "# Colors associated with class identifiers.\n",
        "FULL_COLOR_MAP = label_to_color_image(FULL_LABEL_MAP)\n",
        "\n",
        "for label, color in zip(FULL_LABEL_MAP, FULL_COLOR_MAP):\n",
        "  print(label, color)"
      ],
      "metadata": {
        "id": "rJzTP4Cz5iZq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "93143829-d95f-4c05-fcc0-47b7e3ba9eef"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0] [[128  64 128]]\n",
            "[1] [[244  35 232]]\n",
            "[2] [[70 70 70]]\n",
            "[3] [[102 102 156]]\n",
            "[4] [[190 153 153]]\n",
            "[5] [[153 153 153]]\n",
            "[6] [[250 170  30]]\n",
            "[7] [[220 220   0]]\n",
            "[8] [[120 155  42]]\n",
            "[9] [[152 251 152]]\n",
            "[10] [[ 93 165 227]]\n",
            "[11] [[220  20  60]]\n",
            "[12] [[255   0   0]]\n",
            "[13] [[ 34  34 142]]\n",
            "[14] [[ 0  0 70]]\n",
            "[15] [[  0  60 100]]\n",
            "[16] [[  0  80 100]]\n",
            "[17] [[  0   0 230]]\n",
            "[18] [[119  11  32]]\n",
            "[19] [[0 0 0]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Pre-trained files"
      ],
      "metadata": {
        "id": "NVXhcs7mNXpA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "MODEL_URL = 'http://download.tensorflow.org/models/deeplabv3_cityscapes_train_2018_02_06.tar.gz'"
      ],
      "metadata": {
        "id": "hSNr9_5m5iW1"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "TARBALL_NAME = 'deeplab_model.tar.gz'\n",
        "model_dir = tempfile.mkdtemp()\n",
        "tf.io.gfile.makedirs(model_dir)"
      ],
      "metadata": {
        "id": "utqhfnYz94ht"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "download_path = os.path.join(model_dir, TARBALL_NAME)\n",
        "download_path"
      ],
      "metadata": {
        "id": "OAfHbuaO94e3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "1172dc98-a864-496f-dc24-a4a9d6f8d524"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/tmp/tmpkkdwpewi/deeplab_model.tar.gz'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "urllib.request.urlretrieve(MODEL_URL, download_path)"
      ],
      "metadata": {
        "id": "iySvBRW294cZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f28e4e25-9fe5-45b1-d4d5-dcfb238f19de"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('/tmp/tmpkkdwpewi/deeplab_model.tar.gz',\n",
              " <http.client.HTTPMessage at 0x7f79058ed8e0>)"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create the model"
      ],
      "metadata": {
        "id": "TsPb4dzevGbw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = DeepLabModel(download_path)"
      ],
      "metadata": {
        "id": "z4A3JVfE94aa"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model test"
      ],
      "metadata": {
        "id": "L-fckyyMwz-U"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Load the video test"
      ],
      "metadata": {
        "id": "oxRAWN_pxKZl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://github.com/lexfridman/mit-deep-learning/raw/master/tutorial_driving_scene_segmentation/mit_driveseg_sample.mp4"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sADOatXBNiCR",
        "outputId": "0f4d05cf-dcad-44be-8613-bd7e71483ea9"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-12-28 23:31:49--  https://github.com/lexfridman/mit-deep-learning/raw/master/tutorial_driving_scene_segmentation/mit_driveseg_sample.mp4\n",
            "Resolving github.com (github.com)... 140.82.121.3\n",
            "Connecting to github.com (github.com)|140.82.121.3|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/lexfridman/mit-deep-learning/master/tutorial_driving_scene_segmentation/mit_driveseg_sample.mp4 [following]\n",
            "--2022-12-28 23:31:49--  https://raw.githubusercontent.com/lexfridman/mit-deep-learning/master/tutorial_driving_scene_segmentation/mit_driveseg_sample.mp4\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 28576737 (27M) [application/octet-stream]\n",
            "Saving to: ‘mit_driveseg_sample.mp4’\n",
            "\n",
            "\rmit_driveseg_sample   0%[                    ]       0  --.-KB/s               \rmit_driveseg_sample 100%[===================>]  27.25M  --.-KB/s    in 0.08s   \n",
            "\n",
            "2022-12-28 23:31:49 (350 MB/s) - ‘mit_driveseg_sample.mp4’ saved [28576737/28576737]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "bzdHF14-Nj7H"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "### Result & Segmentation visualization"
      ],
      "metadata": {
        "id": "Lp-sDScjxK3j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def video_segmentation_vis(image, segmentation_map, index):\n",
        "    plt.figure(figsize=(12, 7))\n",
        "\n",
        "    seg_image = label_to_color_image(segmentation_map).astype(np.uint8)\n",
        "    plt.imshow(image)\n",
        "    plt.imshow(seg_image, alpha=0.7)\n",
        "    plt.axis('off')\n",
        "    plt.title('Segmentation | frame #%d'%index)\n",
        "    plt.grid('off')\n",
        "    plt.tight_layout()\n",
        " \n",
        "    f = BytesIO()\n",
        "    plt.savefig(f, format='jpeg')\n",
        "    IPython.display.display(IPython.display.Image(data=f.getvalue()))\n",
        "    f.close()\n",
        "    plt.close()\n",
        "\n",
        "    segmentated_image = cv2.addWeighted(np.uint8(image), 0.3, np.uint8(seg_image), 0.7, 0)\n",
        "    return segmentated_image"
      ],
      "metadata": {
        "id": "HpDyryvpCIXu"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def run_video_vis(frame, index):\n",
        "    original_image = Image.fromarray(frame[..., ::-1])\n",
        "    segmentated_map = model.run(original_image)\n",
        "    segmentated_frame = video_segmentation_vis(original_image, segmentated_map, index)\n",
        "    segmentated_frame = cv2.cvtColor(segmentated_frame, cv2.COLOR_RGB2BGR)\n",
        "    return segmentated_frame"
      ],
      "metadata": {
        "id": "zkUzxze2CoiQ"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def video_config(width, height, filename='result.avi'): \n",
        "  fourcc = cv2.VideoWriter_fourcc(*'XVID') \n",
        "  fps = 24\n",
        "  output = cv2.VideoWriter(filename, fourcc, fps, (width, height))\n",
        "  return output"
      ],
      "metadata": {
        "id": "Myx-cg7JDpkl"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "video_test = 'mit_driveseg_sample.mp4'\n",
        "\n",
        "cap = cv2.VideoCapture(video_test)\n",
        "num_frames = 598\n",
        "initial_frame = 0\n",
        "current_frame = 0 \n",
        "\n",
        "connected, video = cap.read()\n",
        "width, height = video.shape[1], video.shape[0]\n",
        "video_output = video_config(width, height)\n",
        "\n",
        "try:\n",
        "    for i in range(num_frames):\n",
        "      _, frame = cap.read()\n",
        "      if not _: break\n",
        "\n",
        "      if i < initial_frame:\n",
        "        continue\n",
        "      processed_frame = run_video_vis(frame, i)\n",
        "      IPython.display.clear_output(wait=True)\n",
        "      current_frame = current_frame + 1\n",
        "      video_output.write(processed_frame) \n",
        "\n",
        "except KeyboardInterrupt:\n",
        "    plt.close()\n",
        "    print(\"Stream stopped.\")\n",
        "\n",
        "\n",
        "print(\"The end!\")\n",
        "video_output.release() "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "RXR4Xh7QCoYV",
        "outputId": "580d4114-852d-4ab7-b897-ba31fa9f8355"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The end!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "lTtZk0vwFwDE"
      },
      "execution_count": 15,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}